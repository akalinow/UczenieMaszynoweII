{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "## Inicjalizacja środowiska programistycznego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Color printing\n",
    "from termcolor import colored\n",
    "\n",
    "#General data operations library\n",
    "import math\n",
    "import string\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "#The tensorflow library\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "import tensorflow  as tf\n",
    "\n",
    "#Plotting libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Increase plots font size\n",
    "params = {'legend.fontsize': 'xx-large',\n",
    "          'figure.figsize': (10, 7),\n",
    "         'axes.labelsize': 'xx-large',\n",
    "         'axes.titlesize':'xx-large',\n",
    "         'xtick.labelsize':'xx-large',\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "plt.rcParams.update(params) \n",
    "\n",
    "#append path with python modules\n",
    "import importlib\n",
    "import sys\n",
    "sys.path.append(\"../modules\")\n",
    "\n",
    "#Private functions\n",
    "import plotting_functions as plf\n",
    "importlib.reload(plf);\n",
    "\n",
    "#Hide GPU\n",
    "#tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<br/><br/>\n",
    "<br/><br/>\n",
    "\n",
    "<h1 align=\"center\">\n",
    " Uczenie maszynowe II\n",
    "</h1>\n",
    "\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "\n",
    "<h1 align=\"right\">\n",
    "Artur Kalinowski <br>\n",
    "Uniwersytet Warszawski <br>\n",
    "Wydział Fizyki <br>    \n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Dane w postaci pary macierzy `x,y` są mało wydajne w sytuacji gdy jest ich dużo lub są rozmieszczone w wielu plikach.\n",
    "TF dostarcza dedykowaną klasę do obsługi strumienia wejścia:\n",
    "```Python\n",
    "tf.data.Dataset(variant_tensor)\n",
    "```\n",
    "\n",
    "Klasa `tf.Dataset` pozwala na zaawansowane operacje na danych. Implementacja tych operacji korzysta równoległego przetwarzania danych w celu zwiększenia przepustowości strumienia wejścia: `liczby przykładów na sekundę`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "Obiekt `tf.Dataset` można tworzyć na wiele sposobów:\n",
    "\n",
    "* z macierzy:\n",
    "\n",
    "```Python\n",
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "```\n",
    "\n",
    "* z funkcji typu generator\n",
    "\n",
    "```Python\n",
    "dataset = tf.data.Dataset.from_generator(...)\n",
    "```\n",
    "\n",
    "* z pliku typu CSV\n",
    "\n",
    "```Python\n",
    "dataset = tf.data.TextLineDataset(...)\n",
    "```\n",
    "\n",
    "* z pliku zawierającego dane w dedykowanym formacie `TFRecord`\n",
    "\n",
    "```Python\n",
    "dataset = tf.data.TFRecordDataset([\"file1.tfrecords\", \"file2.tfrecords\"])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Konstrukcja `tf.data.Dataset` z macierzy NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nExamples = 5\n",
    "nFeatures = 3\n",
    "epsilon = 0.01\n",
    "x = tf.random.uniform((nExamples, nFeatures), minval=-1, maxval=1, dtype=tf.float32, name=\"features\")\n",
    "y = tf.math.reduce_sum(x**2, axis=1)\n",
    "y = tf.reshape(y, (-1, 1))\n",
    "\n",
    "print(colored(\"Features shape:\", \"blue\"), x.shape)\n",
    "print(colored(\"Labels shape:\", \"blue\"), y.shape)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "print(dataset)\n",
    "print(colored(\"Dataset lenght:\", \"blue\"), len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.Dataset` zachowuje się jak kolekcja - można po niej iterować łatwo dostosowując liczbę analizowanych elementów i punkt startowy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(colored(\"Iteration over the full dataset\", \"blue\"))\n",
    "for item in dataset:\n",
    "    print(item)\n",
    "\n",
    "print(colored(\"Iteration over n elements\", \"blue\"))\n",
    "n = 3\n",
    "for item in dataset.take(n):\n",
    "    print(item)\n",
    "\n",
    "print(colored(\"Iteration over n elements starting from m\", \"blue\"))\n",
    "n = 3\n",
    "m = 2\n",
    "for item in dataset.skip(m).take(n):\n",
    "    print(item)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Konstrukcja `tf.Dataset` z funkcji generującej.\n",
    "\n",
    "W tym wypadku oprócz funkcji generującej musimy podać informacje o kształcie i typie danych generowanych przez funkcję:\n",
    "```Python\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "         generator,                                      # funkcja generująca\n",
    "         output_signature=(                              # opis kształtu i typu\n",
    "             (tf.TensorSpec(shape=(3), dtype=tf.float32),# danych generowanych\n",
    "             tf.TensorSpec(shape=(1), dtype=tf.int32)))  # przez funkcję\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Generator function definition\n",
    "nFeatures = 3\n",
    "\n",
    "def points3DGenerator():\n",
    "    while True:\n",
    "        x = tf.random.uniform(shape=(nFeatures,), minval=-1, maxval=1, dtype=tf.float32, name=\"features\")\n",
    "        y = tf.math.reduce_sum(x**2, axis=0)\n",
    "        y = tf.reshape(y, (1))\n",
    "        yield x,y\n",
    "\n",
    "#Dataset from generator\n",
    "dataset = tf.data.Dataset.from_generator(points3DGenerator,\n",
    "         output_signature=(\n",
    "             (tf.TensorSpec(shape=(nFeatures,), dtype=tf.float32, name=\"features\"),\n",
    "             tf.TensorSpec(shape=(1), dtype=tf.float32, name=\"labels\")))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(colored(\"Iteration over n elements starting from m\", \"blue\"))\n",
    "n = 3\n",
    "m = 2\n",
    "for item in dataset.skip(m).take(n):\n",
    "    print(item) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Na zbiorze `tf.Dataset` można wykonywać różne operacje przekształcenia:\n",
    "\n",
    "```Python\n",
    "dataset = dataset.repeat(n) - # powtarza dane n razy\n",
    "                              # W sytuacji gdy nie podano argumentu\n",
    "                              # dane są powtarzane w nieskończoność.\n",
    "```\n",
    "\n",
    "**Uwaga:** nie trzeba używać `repeat` by uzyskać wiele epok w czasie treningu. Funkcja `model.fit(...)` \n",
    "sama zarządza wielokrotnymi przejściami przez zbiór danych\n",
    "\n",
    "```Python\n",
    "dataset = dataset.batch(n)   - # grupowanie zbioru w paczki. \n",
    "                               # W czasie treningu paczki są automatycznie \n",
    "                               # rozpoznane i nie trzeba (nie wolno) podawać \n",
    "                               # rozmiaru paczki explicite. \n",
    "```\n",
    "\n",
    "```Python\n",
    "dataset = dataset.skip(m)    - # opuszcza pierwsze m przykładów\n",
    "                              \n",
    "```\n",
    "\n",
    "```Python\n",
    "dataset = dataset.take(n)    - # ogranicza zbiór do pierwszych n przykładów\n",
    "                              \n",
    "```\n",
    "\n",
    "```Python\n",
    "dataset = dataset.skip(m).take(n)    - # opuszcza pierwsze m, i bierze \n",
    "                                       # kolejne n przykładów\n",
    "                              \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_batched = dataset.batch(2)\n",
    "\n",
    "#Access a single example (batch in this case)\n",
    "it = iter(dataset_batched)\n",
    "print(colored(\"Features shape:\", \"blue\"), next(it)[0].numpy().shape)\n",
    "print(colored(\"Labels shape:\", \"blue\"), next(it)[1].numpy().shape)\n",
    "\n",
    "print(colored(\"Iteration over n elements starting from m\", \"blue\"))\n",
    "m = 5\n",
    "n = 1\n",
    "for item in dataset_batched.skip(m).take(n):\n",
    "    print(colored(\"\\tLabels:\",\"blue\"),item[0].numpy())\n",
    "    print(colored(\"\\tFeatures:\",\"blue\"),item[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Zbiór danych można poddać też ogólnej transformacji zmieniającej zawartość poszczególnych wierszy:\n",
    "```Python\n",
    "dataset_transformed = dataset.map(func) # func to funkcja przyjmująca dany wiersz i zwracająca nowy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def func(features, label):\n",
    "    return features**2, label\n",
    "\n",
    "dataset_transformed = dataset.map(func)\n",
    "\n",
    "print(colored(\"Iteration over original dataset\", \"blue\"))\n",
    "for item in dataset.skip(m).take(n):\n",
    "    print(colored(\"\\tLabels:\",\"blue\"),item[0].numpy())\n",
    "    print(colored(\"\\tFeatures:\",\"blue\"),item[1].numpy())\n",
    "\n",
    "print(colored(\"Iteration over transformed dataset\", \"blue\"))\n",
    "for item in dataset_transformed.skip(m).take(n):\n",
    "    print(colored(\"\\tLabels:\",\"blue\"),item[0].numpy())\n",
    "    print(colored(\"\\tFeatures:\",\"blue\"),item[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Proszę:**\n",
    "\n",
    "* skopiować funkcję `discGenerator` z poprzednich zajęć\n",
    "* stworzyć zbiór `tf.Dataset` obrazów kół korzystając bezpośrednio z generatora. Proszę przyjąć rozdzielczość 256 $\\times$ 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def discGenerator(res=256):\n",
    "\n",
    "    from skimage.draw import disk\n",
    "    while True:\n",
    "        center = tf.random.uniform([2], minval=0, maxval = res, dtype=tf.int32, name='center')\n",
    "        radius = tf.random.uniform([1], minval=5, maxval = res//2, dtype=tf.int32, name='radius')        \n",
    "        shape = (res, res)\n",
    "        image = np.full(shape, 0)\n",
    "        yy, xx = disk(center=center.numpy(), radius=radius.numpy()[0], shape=shape)\n",
    "        image[xx,yy] = 1\n",
    "        features = tf.concat(values=(center, radius), axis=0 )\n",
    "        label = tf.constant(image, dtype=tf.int32, name='image')\n",
    "        label = tf.reshape(label, (res, res, 1))\n",
    "        yield  features, label\n",
    "\n",
    "#BEGIN_SOLUTION\n",
    "res = 256\n",
    "dataset = tf.data.Dataset.from_generator(discGenerator,\n",
    "         output_signature=(\n",
    "             (tf.TensorSpec(shape=(3), dtype=tf.int32),\n",
    "             tf.TensorSpec(shape=(res,res,1), dtype=tf.int32)))\n",
    "    )\n",
    "#END_SOLUTION\n",
    "\n",
    "item = next(iter(dataset))\n",
    "print(colored(\"Features shape:\", \"blue\"), item[0].shape)\n",
    "print(colored(\"Labels shape:\", \"blue\"), item[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Proszę:**\n",
    "\n",
    "* napisać funkcję `reading_benchmark(dataset)` która przyjmuje zbiór danych, iteruje po całym zbiorze i oblicza i \n",
    "   wypisuje na ekran swój czas wykonania\n",
    "* w iteracjach po elementach zbioru proszę wstawić krótki postój:\n",
    "```Python\n",
    "time.sleep(1E-10)\n",
    "```\n",
    "* proszę wywołać funkcję na zbiorze który ma $10^{4}$ elementów i zarejestrować czas przebiegu po zbiorze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def reading_benchmark(dataset):\n",
    "#BEGIN_SOLUTION \n",
    "    start_time = time.perf_counter()\n",
    "    for sample in dataset:\n",
    "        # Performing a training step\n",
    "        time.sleep(1E-10)\n",
    "    tf.print(\"Execution time: {:3.2f} s\".format(time.perf_counter() - start_time))\n",
    "\n",
    "\n",
    "reading_benchmark(dataset.take(int(1E4)))    \n",
    "#END_SOLUTION    \n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Generacja danych za każdym razem kiedy jest wywoływana iteracja po zbiorze jest kosztowana - \n",
    "lepiej wygenerować dane raz i je zapisać w pamięci podręcznej. To samo dotyczy zbiorów czytanych z dysku i \n",
    "poddawanych kosztownym operacjom przekształcania. Zapisywanie zbioru w tymczasowym pliku można uzyskać przez metodę `cache`:\n",
    "```Python\n",
    "dataset_cached = dataset.cache()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Proszę:**\n",
    "\n",
    "* wywołać dwa razy funkcję `reading_benchmark` na zbiorze `dataset_cached`\n",
    "* czy jest jakaś różnica w czasie wykonania?\n",
    "* jeśli tak, to skąd się ona bierze?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#BEGIN_SOLUTION\n",
    "dataset_cached = dataset.take(int(1E4)).cache()\n",
    "\n",
    "print(colored(\"First pass\", \"blue\"))\n",
    "reading_benchmark(dataset_cached)\n",
    "print(colored(\"Second pass\", \"blue\"))\n",
    "reading_benchmark(dataset_cached)\n",
    "#END_SOLUTION\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Każdy wiersz danych w postaci `tf.Dataset` powinien zawierać cechy i etykiety by można go było przekazać do funkcji trenującej model:\n",
    "```Python\n",
    "model.fit(dataset, ...)  #Podajemy tylko tf.Dataset. \n",
    "                         #Metoda model.fit(...) sama rozkłada każdy wiersz na cechy i etykiety\n",
    "```\n",
    "\n",
    "Jeśli `tf.Dataset` pochodzi z generatora, jako dane walidacyjne najlepiej podać nowy zbiór. \n",
    "W tej sytuacji trzeba także podać liczbę przykładów dla obu zbiorów:\n",
    "\n",
    "```Python\n",
    "model.fit(dataset.batch(batchSize).take(nStepsPerEpoch),\n",
    "          epochs=nEpochs, \n",
    "          validation_data=dataset.batch(batchSize).map(mapFunc).take(100))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Proszę:**\n",
    "\n",
    "* wytrenować **minimalny** model obliczający kwadrat odległości punktu od środka układu współrzędnych\n",
    "* jako zbiorów uczacego, walidacyjnego i testowego proszę użyć obiektów `tf.Dataset` wypełnionych z użyciem generatora `points3DGenerator(...)`\n",
    "* użyć funkcji przekształcającej etykietę do wymaganej postaci z użyciem `tf.Dataset.map(...)`\n",
    "* przyjąć następujące parametry treningu:\n",
    "```Python\n",
    "nEpochs = 5\n",
    "nStepsPerEpoch = 4096\n",
    "batchSize = 32\n",
    "initial_learning_rate = 5E-2\n",
    "```\n",
    "* narysować historię treningu\n",
    "* wypisać wagi modelu w sposób pozwalający na interpretację\n",
    "* obliczyć ułamek przykładów ze zbioru testowego dla którego wynik modelu różni się od etykiety o nie więcej niż 1%\n",
    "\n",
    "**Wskazówka:**\n",
    "wartości etykiet można wydobyć w następujący (suboptymalny) sposób:\n",
    "```Python\n",
    "y = np.array([y.numpy() for x,y in dataset_test.unbatch()])\n",
    "```\n",
    "\n",
    "**Uwaga:** trening powinien zająć około 3'\n",
    "\n",
    "Czy wynik na zbiorze testowym jest zgodny z oczekiwaniem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Przygotowanie danych z generatora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##BEGIN_SOLUTION\n",
    "dataset = tf.data.Dataset.from_generator(points3DGenerator,\n",
    "         output_signature=(\n",
    "             (tf.TensorSpec(shape=(nFeatures,), dtype=tf.float32, name=\"features\"),\n",
    "             tf.TensorSpec(shape=(1), dtype=tf.float32, name=\"labels\")))\n",
    "    )\n",
    "##END_SOLUTION\n",
    "item = next(iter(dataset))\n",
    "print(colored(\"Features shape:\", \"blue\"), item[0].shape)\n",
    "print(colored(\"Labels shape:\", \"blue\"), item[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) przygotowanie danych\n",
    "\n",
    "* podział na paczki\n",
    "* modyfikacja zawartości danych z użyciem `dataset.map(...)`.\n",
    "* przygotowanie odpowiedniej liczby przykładów\n",
    "* buforowanie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEGIN_SOLUTION\n",
    "nStepsPerEpoch = 4096\n",
    "batchSize = 64\n",
    "dataset_train = dataset.batch(batchSize).map(func).take(nStepsPerEpoch).cache()\n",
    "#END_SOLUTION\n",
    "\n",
    "item = next(iter(dataset_train))\n",
    "print(colored(\"Features shape:\", \"blue\"), item[0].shape)\n",
    "print(colored(\"Labels shape:\", \"blue\"), item[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) definicja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#BEGIN_SOLUTION\n",
    "def getModel(inputShape, nNeurons, hiddenActivation=\"relu\", outputActivation=\"linear\", nOutputNeurons=1):\n",
    "   \n",
    "    inputs = tf.keras.Input(shape=inputShape, name=\"features\")\n",
    "    x = inputs\n",
    "    \n",
    "    for iLayer, n in enumerate(nNeurons):\n",
    "        x = tf.keras.layers.Dense(n, activation=hiddenActivation, \n",
    "                                  kernel_initializer='glorot_uniform',\n",
    "                                  bias_initializer=tf.keras.initializers.RandomUniform(minval=-1, maxval=1),\n",
    "                                  kernel_regularizer=tf.keras.regularizers.L2(l2=0.001),\n",
    "                                  name=\"layer_\"+str(iLayer))(x)\n",
    "                \n",
    "    outputs = tf.keras.layers.Dense(nOutputNeurons, activation=outputActivation, name = \"output\")(x)   \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"DNN\")\n",
    "    return model\n",
    "\n",
    "model = getModel(inputShape=(nFeatures,), nNeurons = np.array([]), \n",
    "                 hiddenActivation=\"relu\", \n",
    "                 outputActivation=\"linear\", \n",
    "                 nOutputNeurons=1)\n",
    "#END_SOLUTION\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) trening ze wszystkimi standardowymi elementami:\n",
    "* harmonogram współczynnika uczenia\n",
    "* wczesne zatrzymanie\n",
    "* wykres zmiany funkcji straty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEGIN_SOLUTION\n",
    "nEpochs = 5\n",
    "\n",
    "initial_learning_rate = 5E-2\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate,\n",
    "                decay_steps=nStepsPerEpoch*3,\n",
    "                decay_rate=0.95,\n",
    "                staircase=True)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "            loss=tf.keras.losses.MeanAbsolutePercentageError(),\n",
    "            metrics=[])\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, min_delta=1E-3)\n",
    "callbacks = [early_stop_callback]\n",
    "    \n",
    "history = model.fit(dataset_train.skip(batchSize*4),\n",
    "                    epochs=nEpochs, \n",
    "                    validation_data=dataset_train.take(batchSize*4),\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1)\n",
    "\n",
    "model.evaluate(dataset_train.take(16))\n",
    "plf.plotTrainHistory(history)\n",
    "\n",
    "print(colored(\"Model weights:\",\"blue\"))\n",
    "print(colored(\"output:\",\"blue\"), model.get_layer('output').weights[0].numpy()[:,0])\n",
    "#END_SOLUTION\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) oszacowanie wydajności modelu na danych testowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEGIN_SOLUTION\n",
    "dataset_test = dataset.batch(128).map(func).take(16)\n",
    "y_pred = model.predict(dataset_test)\n",
    "y = np.array([y.numpy() for x,y in dataset_test.unbatch()])\n",
    "\n",
    "pull = (y_pred - y)/y\n",
    "pull = pull.flatten()\n",
    "threshold = 1E-2\n",
    "\n",
    "print(colored(\"Fraction of examples with abs(pull)<0.01:\",\"blue\"),\"{:3.2f}\".format(np.mean(np.abs(pull)<threshold)))\n",
    "print(colored(\"Pull standard deviation:\",\"blue\"),\"{:3.2f}\".format(pull.std()))\n",
    "#END_SOLUTION\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Proszę:**\n",
    "\n",
    "* rozwiązać problem z różnicą wyników na zbiorach treningowym i testowym\n",
    "* narysować histogram różnicy względnej:\n",
    "\n",
    "$$\n",
    "{\\huge\n",
    "\\mathrm{pull} = \\frac{\\mathrm{model} - \\mathrm{true}}{\\mathrm{true}}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#BEGIN_SOLUTION\n",
    "dataset_test = dataset.batch(128).map(func).take(32).cache()\n",
    "y_pred = model.predict(dataset_test)\n",
    "y = np.array([y.numpy() for x,y in dataset_test.unbatch()])\n",
    "\n",
    "pull = (y_pred - y)/y\n",
    "pull = pull.flatten()\n",
    "threshold = 1E-2\n",
    "\n",
    "fig, axis = plt.subplots(1,1, figsize=(5, 5))\n",
    "axis.hist(pull, bins=100, range=(-0.01, 0.01), color='b', alpha=0.7, label='Pull');\n",
    "axis.set_xlabel(r'$\\frac{model-true}{true}$')\n",
    "axis.set_ylabel('Counts')\n",
    "model.evaluate(dataset_test)\n",
    "print(colored(\"Fraction of examples with abs(pull)<0.01:\",\"blue\"),\"{:3.4f}\".format(np.mean(np.abs(pull)<threshold)))\n",
    "print(colored(\"Pull standard deviation:\",\"blue\"),\"{:3.4f}\".format(pull.std()))\n",
    "#END_SOLUTION\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Zbiory danych w TensorFlow datasets\n",
    "\n",
    "Środowisko TensorFlow dostarcza wygodnego iterfejsu użytkownika do dostępu do publicznych zbiorów danych (podobnie jak inne pakiety):\n",
    "[TensorFlow Datasets](https://www.tensorflow.org/datasets).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "#Create a dataset builder object\n",
    "mnist_builder = tfds.builder('mnist')\n",
    "\n",
    "#Download the dataset as a dictionary of tf.data.Datasets\n",
    "data_dir = \"../data/tensorflow_datasets/\"\n",
    "\n",
    "datasets, ds_info = tfds.load(\"mnist\", \n",
    "                              data_dir = data_dir,\n",
    "                              with_info=True)\n",
    "\n",
    "#Download the dataset as a tuple of tf.data.Datasets\n",
    "#datasets, ds_info = tfds.load(\"mnist\", as_supervised=True, with_info=True)\n",
    "\n",
    "# Load data from disk as tf.data.Datasets\n",
    "train_dataset, test_dataset = datasets['train'], datasets['test']\n",
    "\n",
    "# Fetch the first batch of the dataset\n",
    "item = next(iter(train_dataset.batch(16)))\n",
    "\n",
    "print(colored(\"Features shape:\", \"blue\"), item['image'].shape)\n",
    "print(colored(\"Labels shape:\", \"blue\"), item['label'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Biblioteka `tensorflow_datasets` dostarcza użytecznej funkcji do testu  wydajności wczytytywania zbioru danych:\n",
    "\n",
    "```Python\n",
    "tfds.benchmark(train_dataset, # Obiekt który dostarcza interfejsu iteratora\n",
    "                batch_size)   # Liczba służąca do normalizacji liczby wczytanych przykładów. \n",
    "                              # Podział na paczki trzeba ustawić na zbiorze explicite.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Proszę:**\n",
    "\n",
    "* uruchomić dwukrotnie test wydajności na zbiorze MNIST wczytanym z użyciem modułu `tensorflow_datasets` dla paczki o rozmiarze `32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#BEGIN_SOLUTION\n",
    "batchSize = 32\n",
    "train_dataset_batched = train_dataset.batch(batchSize)\n",
    "\n",
    "tfds.benchmark(train_dataset_batched, batch_size=batchSize)\n",
    "tfds.benchmark(train_dataset_batched, batch_size=batchSize)\n",
    "#END_SOLUTION\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Funkcja `tfds.show_examples(...)` pozwala na szybkie wyświetlenie przykładów z podanego zbioru.\n",
    "\n",
    "**Uwaga:** funkcja wymaga obiektu `dataset_info.DatasetInfo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = tfds.show_examples(train_dataset, ds_info, rows=2, cols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Zadanie domowe\n",
    "\n",
    "**Proszę:**\n",
    "\n",
    "* napisać funkcję `load_wksf_dataset(filePath)` wczytującą i wstępnie przetwarzającą  zbiór fragmentów tekstow w języku [polskim](https://drive.google.com/drive/folders/18vDJPEZd2C6_-TualBIhsR5zmbhDA00D?usp=drive_link) pochodzący ze [Wzbogaconego korpusu słownika frekwencyjnego polszczyzny współczesnej](https://clarin-pl.eu/dspace/handle/11321/715)\n",
    "* funkcja powinna wykonywać następujące kroki:\n",
    "  * wczytywanie wszystkich plików w katalogu podanym jako `filePath` do obiektu `tf.data.Dataset` \n",
    "  * przetwarzanie powstałego obiekty `tf.data.Dataset` by usunąć:\n",
    "    * informację o źródle cytatu\n",
    "    * odnośniki w tekście\n",
    "    * fragmenty typu `[/]` \n",
    "\n",
    "* funkcję należy umieścić w pliku `text_functions.py`\n",
    " * uruchomić komórkę poniżej\n",
    " \n",
    "**Wskazówka:**\n",
    "* mozna użyć funkcji `tf.strings.regex_full_match(...)` oraz `tf.strings.regex_replace(...)` do filtrowania linii lub zastępowania\n",
    "  fragmentów napisów\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import text_functions as txtfunc\n",
    "importlib.reload(txtfunc)\n",
    "\n",
    "filePath = \"../data/wksf/Korpus_surowy/\"\n",
    "dataset = txtfunc.load_wksf_dataset(filePath)\n",
    "\n",
    "for item in dataset.take(5):\n",
    "    print(colored(\"Item:\",\"blue\"), end=\" \")\n",
    "    print(item.numpy().decode(\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "01_Pakiety_numpy_pandas.ipynb",
   "provenance": [
    {
     "file_id": "0BzwQ_Lscn8yDWnZVeHU1MjluWFU",
     "timestamp": 1546856440599
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "rise": {
   "center": false,
   "controls": false,
   "footer": "<h3>Letnia Szkoła<br>Fizyki 2023</h3>",
   "header": "<h1>Hello</h1>",
   "progress": "true",
   "slideNumber": "c/t",
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
