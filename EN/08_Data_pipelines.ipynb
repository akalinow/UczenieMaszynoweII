{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "## Initialization of programming env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Color printing\n",
    "from termcolor import colored\n",
    "\n",
    "#General data operations library\n",
    "import math\n",
    "import string\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "#The tensorflow library\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "import tensorflow  as tf\n",
    "\n",
    "#Plotting libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Increase plots font size\n",
    "params = {'legend.fontsize': 'xx-large',\n",
    "          'figure.figsize': (10, 7),\n",
    "         'axes.labelsize': 'xx-large',\n",
    "         'axes.titlesize':'xx-large',\n",
    "         'xtick.labelsize':'xx-large',\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "plt.rcParams.update(params) \n",
    "\n",
    "#append path with python modules\n",
    "import importlib\n",
    "import sys\n",
    "sys.path.append(\"../modules\")\n",
    "\n",
    "#Private functions\n",
    "import plotting_functions as plf\n",
    "importlib.reload(plf);\n",
    "\n",
    "#Hide GPU\n",
    "#tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<br/><br/>\n",
    "<br/><br/>\n",
    "\n",
    "<h1 align=\"center\">\n",
    " Machine learning II\n",
    "</h1>\n",
    "\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "\n",
    "<h1 align=\"right\">\n",
    "Artur Kalinowski <br>\n",
    "University of Warsaw <br>\n",
    "Faculty of Physics <br>    \n",
    "</h1>\n",
    "\n",
    "Data in the form of a pair of `x,y` matrices is inefficient when there is a lot of data or it is spread over many files.\n",
    "TF provides a dedicated class to handle the input stream:\n",
    "```Python\n",
    "tf.data.Dataset(variant_tensor)\n",
    "```\n",
    "\n",
    "The `tf.Dataset` class allows advanced operations on data. The implementation of these operations uses parallel data processing to increase the throughput of the input stream: `number of examples per second`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "The `tf.Dataset` object can be created:\n",
    "\n",
    "* from matrix:\n",
    "\n",
    "```Python\n",
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "```\n",
    "\n",
    "* from generator type function\n",
    "\n",
    "```Python\n",
    "dataset = tf.data.Dataset.from_generator(...)\n",
    "```\n",
    "\n",
    "* from CSV file\n",
    "\n",
    "```Python\n",
    "dataset = tf.data.TextLineDataset(...)\n",
    "```\n",
    "\n",
    "* from file contatining data in dedicated `TFRecord` format\n",
    "\n",
    "```Python\n",
    "dataset = tf.data.TFRecordDataset([\"file1.tfrecords\", \"file2.tfrecords\"])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Constructing `tf.data.Dataset` from NumPy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nExamples = 5\n",
    "nFeatures = 3\n",
    "epsilon = 0.01\n",
    "x = tf.random.uniform((nExamples, nFeatures), minval=-1, maxval=1, dtype=tf.float32, name=\"features\")\n",
    "y = tf.math.reduce_sum(x**2, axis=1)\n",
    "y = tf.reshape(y, (-1, 1))\n",
    "\n",
    "print(colored(\"Features shape:\", \"blue\"), x.shape)\n",
    "print(colored(\"Labels shape:\", \"blue\"), y.shape)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "print(dataset)\n",
    "print(colored(\"Dataset lenght:\", \"blue\"), len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.Dataset` behaves like a collection - you can iterate through it, easily adjusting the number of elements to be analysed and the starting point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(colored(\"Iteration over the full dataset\", \"blue\"))\n",
    "for item in dataset:\n",
    "    print(item)\n",
    "\n",
    "print(colored(\"Iteration over n elements\", \"blue\"))\n",
    "n = 3\n",
    "for item in dataset.take(n):\n",
    "    print(item)\n",
    "\n",
    "print(colored(\"Iteration over n elements starting from m\", \"blue\"))\n",
    "n = 3\n",
    "m = 2\n",
    "for item in dataset.skip(m).take(n):\n",
    "    print(item)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Constructing `tf.Dataset` from generating function.\n",
    "\n",
    "In this case, in addition to the generating function, we need to provide information about the shape and type of data generated by the function:\n",
    "```Python\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "         generator,                                      # generating function\n",
    "         output_signature=(                              # shape and type\n",
    "             (tf.TensorSpec(shape=(3), dtype=tf.float32),# of the data generated\n",
    "             tf.TensorSpec(shape=(1), dtype=tf.int32)))  # by function\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Generator function definition\n",
    "nFeatures = 3\n",
    "\n",
    "def points3DGenerator():\n",
    "    while True:\n",
    "        x = tf.random.uniform(shape=(nFeatures,), minval=-1, maxval=1, dtype=tf.float32, name=\"features\")\n",
    "        y = tf.math.reduce_sum(x**2, axis=0)\n",
    "        y = tf.reshape(y, (1))\n",
    "        yield x,y\n",
    "\n",
    "#Dataset from generator\n",
    "dataset = tf.data.Dataset.from_generator(points3DGenerator,\n",
    "         output_signature=(\n",
    "             (tf.TensorSpec(shape=(nFeatures,), dtype=tf.float32, name=\"features\"),\n",
    "             tf.TensorSpec(shape=(1), dtype=tf.float32, name=\"labels\")))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(colored(\"Iteration over n elements starting from m\", \"blue\"))\n",
    "n = 3\n",
    "m = 2\n",
    "for item in dataset.skip(m).take(n):\n",
    "    print(item) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Various transformation operations can be performed on the `tf.Dataset`:\n",
    "\n",
    "```Python\n",
    "dataset = dataset.repeat(n) - # repeats data n times\n",
    "                              # When the argument is not given\n",
    "                              # data is repeated ad infinitum\n",
    "```\n",
    "\n",
    "**Note:** it is not necessary to use `repeat` to get multiple epochs during training. The function `model.fit(...)` \n",
    "itself manages multiple passes through the dataset\n",
    "\n",
    "```Python\n",
    "dataset = dataset.batch(n)   - # grouping set into batches\n",
    "                               # During the training batches are\n",
    "                               # automatically recognized, and their \n",
    "                               # sizes do not need to be supplied\n",
    "```\n",
    "\n",
    "```Python\n",
    "dataset = dataset.skip(m)    - # skips first m examples\n",
    "                              \n",
    "```\n",
    "\n",
    "```Python\n",
    "dataset = dataset.take(n)    - # restricts the set to first n examples\n",
    "                              \n",
    "```\n",
    "\n",
    "```Python\n",
    "dataset = dataset.skip(m).take(n)    - # skips first m examples, then\n",
    "                                       # takes in the next n examples\n",
    "                              \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_batched = dataset.batch(2)\n",
    "\n",
    "#Access a single example (batch in this case)\n",
    "it = iter(dataset_batched)\n",
    "print(colored(\"Features shape:\", \"blue\"), next(it)[0].numpy().shape)\n",
    "print(colored(\"Labels shape:\", \"blue\"), next(it)[1].numpy().shape)\n",
    "\n",
    "print(colored(\"Iteration over n elements starting from m\", \"blue\"))\n",
    "m = 5\n",
    "n = 1\n",
    "for item in dataset_batched.skip(m).take(n):\n",
    "    print(colored(\"\\tLabels:\",\"blue\"),item[0].numpy())\n",
    "    print(colored(\"\\tFeatures:\",\"blue\"),item[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "The dataset can also be subjected to a general transformation that changes the content of individual rows:\n",
    "```Python\n",
    "dataset_transformed = dataset.map(func) # func is a function that takes a given row and outputs the new one\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def func(features, label):\n",
    "    return features**2, label\n",
    "\n",
    "dataset_transformed = dataset.map(func)\n",
    "\n",
    "print(colored(\"Iteration over original dataset\", \"blue\"))\n",
    "for item in dataset.skip(m).take(n):\n",
    "    print(colored(\"\\tLabels:\",\"blue\"),item[0].numpy())\n",
    "    print(colored(\"\\tFeatures:\",\"blue\"),item[1].numpy())\n",
    "\n",
    "print(colored(\"Iteration over transformed dataset\", \"blue\"))\n",
    "for item in dataset_transformed.skip(m).take(n):\n",
    "    print(colored(\"\\tLabels:\",\"blue\"),item[0].numpy())\n",
    "    print(colored(\"\\tFeatures:\",\"blue\"),item[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Please:**\n",
    "\n",
    "* copy the `discGenerator` function from the previous classes.\n",
    "* create a `tf.Dataset` set of wheel images using the generator directly. Please assume a resolution of 256 $\\times$ 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def discGenerator(res=256):\n",
    "\n",
    "    from skimage.draw import disk\n",
    "    while True:\n",
    "        center = tf.random.uniform([2], minval=0, maxval = res, dtype=tf.int32, name='center')\n",
    "        radius = tf.random.uniform([1], minval=5, maxval = res//2, dtype=tf.int32, name='radius')        \n",
    "        shape = (res, res)\n",
    "        image = np.full(shape, 0)\n",
    "        yy, xx = disk(center=center.numpy(), radius=radius.numpy()[0], shape=shape)\n",
    "        image[xx,yy] = 1\n",
    "        features = tf.concat(values=(center, radius), axis=0 )\n",
    "        label = tf.constant(image, dtype=tf.int32, name='image')\n",
    "        label = tf.reshape(label, (res, res, 1))\n",
    "        yield  features, label\n",
    "\n",
    "#BEGIN_SOLUTION\n",
    "res = 256\n",
    "dataset = tf.data.Dataset.from_generator(discGenerator,\n",
    "         output_signature=(\n",
    "             (tf.TensorSpec(shape=(3), dtype=tf.int32),\n",
    "             tf.TensorSpec(shape=(res,res,1), dtype=tf.int32)))\n",
    "    )\n",
    "#END_SOLUTION\n",
    "\n",
    "item = next(iter(dataset))\n",
    "print(colored(\"Features shape:\", \"blue\"), item[0].shape)\n",
    "print(colored(\"Labels shape:\", \"blue\"), item[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Please:**\n",
    "\n",
    "* write a function `reading_benchmark(dataset)` that takes a dataset, iterates over the entire dataset, calculates and prints its execution time to the screen\n",
    "* in iterating over the elements of the dataset, please insert a short stop:\n",
    "```Python\n",
    "time.sleep(1E-10)\n",
    "```\n",
    "* please call the function on a set that has $10^{4}$ elements and record the runtime after the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def reading_benchmark(dataset):\n",
    "#BEGIN_SOLUTION \n",
    "    start_time = time.perf_counter()\n",
    "    for sample in dataset:\n",
    "        # Performing a training step\n",
    "        time.sleep(1E-10)\n",
    "    tf.print(\"Execution time: {:3.2f} s\".format(time.perf_counter() - start_time))\n",
    "\n",
    "\n",
    "reading_benchmark(dataset.take(int(1E4)))    \n",
    "#END_SOLUTION    \n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Generacja danych za każdym razem kiedy jest wywoływana iteracja po zbiorze jest kosztowana - \n",
    "lepiej wygenerować dane raz i je zapisać w pamięci podręcznej. To samo dotyczy zbiorów czytanych z dysku i \n",
    "poddawanych kosztownym operacjom przekształcania. Zapisywanie zbioru w tymczasowym pliku można uzyskać przez metodę `cache`:\n",
    "```Python\n",
    "dataset_cached = dataset.cache()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Please:**\n",
    "\n",
    "* call the `reading_benchmark` function twice on the `dataset_cached` collection.\n",
    "* is there any difference in execution time?\n",
    "* if so, where does it come from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#BEGIN_SOLUTION\n",
    "dataset_cached = dataset.take(int(1E4)).cache()\n",
    "\n",
    "print(colored(\"First pass\", \"blue\"))\n",
    "reading_benchmark(dataset_cached)\n",
    "print(colored(\"Second pass\", \"blue\"))\n",
    "reading_benchmark(dataset_cached)\n",
    "#END_SOLUTION\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Each row of data in the form of `tf.Dataset` should contain features and labels to be passed to the function that trains the model:\n",
    "```Python\n",
    "model.fit(dataset, ...)  # Provide only tf.Dataset. \n",
    "                         # model.fit(...) method decomposes each row into features and labels by itself\n",
    "```\n",
    "\n",
    "If the `tf.Dataset` comes from a generator, it is best to provide a new collection as validation data. \n",
    "In this situation, you also need to specify the number of examples for both sets:\n",
    "\n",
    "```Python\n",
    "model.fit(dataset.batch(batchSize).take(nStepsPerEpoch),\n",
    "          epochs=nEpochs, \n",
    "          validation_data=dataset.batch(batchSize).map(mapFunc).take(100))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Please:**\n",
    "\n",
    "* train a **minimal** model that calculates the square of the distance of a point from the centre of the coordinate system.\n",
    "* as learning, validation and test sets, please use `tf.Dataset` objects filled with `points3DGenerator(...)`.\n",
    "* use a function that transforms the label to the required form using `tf.Dataset.map(...)`.\n",
    "* adopt the following training parameters:\n",
    "```Python\n",
    "nEpochs = 5\n",
    "nStepsPerEpoch = 4096\n",
    "batchSize = 32\n",
    "initial_learning_rate = 5E-2\n",
    "```\n",
    "* plot a training history\n",
    "* print out the model weights in a way that allows interpretation\n",
    "* calculate the fraction of examples from the test set for which the model result differs from the label by no more than 1%.\n",
    "\n",
    "**Hint:**\n",
    "label values can be extracted in the following (suboptimal) manner:\n",
    "```Python\n",
    "y = np.array([y.numpy() for x,y in dataset_test.unbatch()])\n",
    "```\n",
    "\n",
    "**Note:** training should take about 3'\n",
    "\n",
    "Is the result on the test set as expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Preparation of data from the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##BEGIN_SOLUTION\n",
    "dataset = tf.data.Dataset.from_generator(points3DGenerator,\n",
    "         output_signature=(\n",
    "             (tf.TensorSpec(shape=(nFeatures,), dtype=tf.float32, name=\"features\"),\n",
    "             tf.TensorSpec(shape=(1), dtype=tf.float32, name=\"labels\")))\n",
    "    )\n",
    "##END_SOLUTION\n",
    "item = next(iter(dataset))\n",
    "print(colored(\"Features shape:\", \"blue\"), item[0].shape)\n",
    "print(colored(\"Labels shape:\", \"blue\"), item[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) data preparation\n",
    "\n",
    "* subdivision into packets\n",
    "* modification of data content using `dataset.map(...)`.\n",
    "* preparing the appropriate number of examples\n",
    "* caching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEGIN_SOLUTION\n",
    "nStepsPerEpoch = 4096\n",
    "batchSize = 64\n",
    "dataset_train = dataset.batch(batchSize).map(func).take(nStepsPerEpoch).cache()\n",
    "#END_SOLUTION\n",
    "\n",
    "item = next(iter(dataset_train))\n",
    "print(colored(\"Features shape:\", \"blue\"), item[0].shape)\n",
    "print(colored(\"Labels shape:\", \"blue\"), item[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#BEGIN_SOLUTION\n",
    "def getModel(inputShape, nNeurons, hiddenActivation=\"relu\", outputActivation=\"linear\", nOutputNeurons=1):\n",
    "   \n",
    "    inputs = tf.keras.Input(shape=inputShape, name=\"features\")\n",
    "    x = inputs\n",
    "    \n",
    "    for iLayer, n in enumerate(nNeurons):\n",
    "        x = tf.keras.layers.Dense(n, activation=hiddenActivation, \n",
    "                                  kernel_initializer='glorot_uniform',\n",
    "                                  bias_initializer=tf.keras.initializers.RandomUniform(minval=-1, maxval=1),\n",
    "                                  kernel_regularizer=tf.keras.regularizers.L2(l2=0.001),\n",
    "                                  name=\"layer_\"+str(iLayer))(x)\n",
    "                \n",
    "    outputs = tf.keras.layers.Dense(nOutputNeurons, activation=outputActivation, name = \"output\")(x)   \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"DNN\")\n",
    "    return model\n",
    "\n",
    "model = getModel(inputShape=(nFeatures,), nNeurons = np.array([]), \n",
    "                 hiddenActivation=\"relu\", \n",
    "                 outputActivation=\"linear\", \n",
    "                 nOutputNeurons=1)\n",
    "#END_SOLUTION\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) training with all the standard elements:\n",
    "* learning rate schedule\n",
    "* early stop\n",
    "* loss function change chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEGIN_SOLUTION\n",
    "nEpochs = 5\n",
    "\n",
    "initial_learning_rate = 5E-2\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate,\n",
    "                decay_steps=nStepsPerEpoch*3,\n",
    "                decay_rate=0.95,\n",
    "                staircase=True)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "            loss=tf.keras.losses.MeanAbsolutePercentageError(),\n",
    "            metrics=[])\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, min_delta=1E-3)\n",
    "callbacks = [early_stop_callback]\n",
    "    \n",
    "history = model.fit(dataset_train.skip(batchSize*4),\n",
    "                    epochs=nEpochs, \n",
    "                    validation_data=dataset_train.take(batchSize*4),\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1)\n",
    "\n",
    "model.evaluate(dataset_train.take(16))\n",
    "plf.plotTrainHistory(history)\n",
    "\n",
    "print(colored(\"Model weights:\",\"blue\"))\n",
    "print(colored(\"output:\",\"blue\"), model.get_layer('output').weights[0].numpy()[:,0])\n",
    "#END_SOLUTION\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) estimation of model performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEGIN_SOLUTION\n",
    "dataset_test = dataset.batch(128).map(func).take(16)\n",
    "y_pred = model.predict(dataset_test)\n",
    "y = np.array([y.numpy() for x,y in dataset_test.unbatch()])\n",
    "\n",
    "pull = (y_pred - y)/y\n",
    "pull = pull.flatten()\n",
    "threshold = 1E-2\n",
    "\n",
    "print(colored(\"Fraction of examples with abs(pull)<0.01:\",\"blue\"),\"{:3.2f}\".format(np.mean(np.abs(pull)<threshold)))\n",
    "print(colored(\"Pull standard deviation:\",\"blue\"),\"{:3.2f}\".format(pull.std()))\n",
    "#END_SOLUTION\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Please:**\n",
    "\n",
    "* solve a problem with the difference in results on the training and test sets.\n",
    "* plot a histogram of the relative difference:\n",
    "\n",
    "$$\n",
    "{\\huge\n",
    "\\mathrm{pull} = \\frac{\\mathrm{model} - \\mathrm{true}}{\\mathrm{true}}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#BEGIN_SOLUTION\n",
    "dataset_test = dataset.batch(128).map(func).take(32).cache()\n",
    "y_pred = model.predict(dataset_test)\n",
    "y = np.array([y.numpy() for x,y in dataset_test.unbatch()])\n",
    "\n",
    "pull = (y_pred - y)/y\n",
    "pull = pull.flatten()\n",
    "threshold = 1E-2\n",
    "\n",
    "fig, axis = plt.subplots(1,1, figsize=(5, 5))\n",
    "axis.hist(pull, bins=100, range=(-0.01, 0.01), color='b', alpha=0.7, label='Pull');\n",
    "axis.set_xlabel(r'$\\frac{model-true}{true}$')\n",
    "axis.set_ylabel('Counts')\n",
    "model.evaluate(dataset_test)\n",
    "print(colored(\"Fraction of examples with abs(pull)<0.01:\",\"blue\"),\"{:3.4f}\".format(np.mean(np.abs(pull)<threshold)))\n",
    "print(colored(\"Pull standard deviation:\",\"blue\"),\"{:3.4f}\".format(pull.std()))\n",
    "#END_SOLUTION\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## TensorFlow datasets\n",
    "\n",
    "The TensorFlow environment provides a convenient user iterface for accessing public datasets (as do other packages):\n",
    "[TensorFlow Datasets](https://www.tensorflow.org/datasets).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "#Create a dataset builder object\n",
    "mnist_builder = tfds.builder('mnist')\n",
    "\n",
    "#Download the dataset as a dictionary of tf.data.Datasets\n",
    "data_dir = \"../data/tensorflow_datasets/\"\n",
    "\n",
    "datasets, ds_info = tfds.load(\"mnist\", \n",
    "                              data_dir = data_dir,\n",
    "                              with_info=True)\n",
    "\n",
    "#Download the dataset as a tuple of tf.data.Datasets\n",
    "#datasets, ds_info = tfds.load(\"mnist\", as_supervised=True, with_info=True)\n",
    "\n",
    "# Load data from disk as tf.data.Datasets\n",
    "train_dataset, test_dataset = datasets['train'], datasets['test']\n",
    "\n",
    "# Fetch the first batch of the dataset\n",
    "item = next(iter(train_dataset.batch(16)))\n",
    "\n",
    "print(colored(\"Features shape:\", \"blue\"), item['image'].shape)\n",
    "print(colored(\"Labels shape:\", \"blue\"), item['label'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "The `tensorflow_datasets` library provides a useful function to test the performance of loading a dataset:\n",
    "\n",
    "```Python\n",
    "tfds.benchmark(train_dataset, # Object that provides the iterator interface.\n",
    "                batch_size)   # A number used to normalise the number of examples loaded. \n",
    "                              # The batch division has to be set on the collection explicite.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Please:**\n",
    "\n",
    "* run the performance test twice on the MNIST set loaded using the `tensorflow_datasets` module for a batch size of `32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#BEGIN_SOLUTION\n",
    "batchSize = 32\n",
    "train_dataset_batched = train_dataset.batch(batchSize)\n",
    "\n",
    "tfds.benchmark(train_dataset_batched, batch_size=batchSize)\n",
    "tfds.benchmark(train_dataset_batched, batch_size=batchSize)\n",
    "#END_SOLUTION\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "The `tfds.show_examples(...)` function allows you to quickly display examples from the given set.\n",
    "\n",
    "**Note:** function requires a `dataset_info.DatasetInfo` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = tfds.show_examples(train_dataset, ds_info, rows=2, cols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Homework\n",
    "\n",
    "**Please:**\n",
    "\n",
    "* write a function `load_wksf_dataset(filePath)` loading and preprocessing a collection of text fragments in [Polish](https://drive.google.com/drive/folders/18vDJPEZd2C6_-TualBIhsR5zmbhDA00D?usp=drive_link) from [Wzbogaconego korpusu słownika frekwencyjnego polszczyzny współczesnej](https://clarin-pl.eu/dspace/handle/11321/715)\n",
    "* the function should perform the following steps:\n",
    "  * loading all files in the directory given as `filePath` into a `tf.data.Dataset` object. \n",
    "  * processing the resulting `tf.data.Dataset` object to remove:\n",
    "    * information about the source of the citation\n",
    "    * references in the text\n",
    "    * fragments of type `[/]`. \n",
    "\n",
    "* the function should be placed in the `text_functions.py` file.\n",
    "* run the cell below\n",
    " \n",
    "**Hint:**\n",
    "* you can use the functions `tf.strings.regex_full_match(...)` and `tf.strings.regex_replace(...)` to filter lines or replace parts of strings\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import text_functions as txtfunc\n",
    "importlib.reload(txtfunc)\n",
    "\n",
    "filePath = \"../data/wksf/Korpus_surowy/\"\n",
    "dataset = txtfunc.load_wksf_dataset(filePath)\n",
    "\n",
    "for item in dataset.take(5):\n",
    "    print(colored(\"Item:\",\"blue\"), end=\" \")\n",
    "    print(item.numpy().decode(\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "01_Pakiety_numpy_pandas.ipynb",
   "provenance": [
    {
     "file_id": "0BzwQ_Lscn8yDWnZVeHU1MjluWFU",
     "timestamp": 1546856440599
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "rise": {
   "center": false,
   "controls": false,
   "footer": "<h3>Letnia Szkoła<br>Fizyki 2023</h3>",
   "header": "<h1>Hello</h1>",
   "progress": "true",
   "slideNumber": "c/t",
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
